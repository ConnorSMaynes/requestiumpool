Metadata-Version: 1.1
Name: requestiumpool
Version: 3.0
Summary: A package for requestium Session pooling.
Home-page: https://github.com/ConnorSMaynes/requestiumpool
Author: ConnorSMaynes
Author-email: connormaynes@gmail.com
License: MIT License
Description-Content-Type: UNKNOWN
Description: # Requestium Pool - Requestium ( requests + selenium + parsel ) + Pooling
        
        ![Requestium](https://user-images.githubusercontent.com/14966348/32966130-8bb15b00-cbb7-11e7-9faf-85963ec5bd82.png | width=100 )
        ![Selenium](http://selenium-python.readthedocs.io/_static/logo.png | width=100 )
        
        Very simple pooling scheme for working with multiple requestium Sessions. Reduce your time costs when running multiple sessions, while sticking to a number of instances you know your machine can handle.
        
        ## Methods
        
        - `acquire()` : get a requestium Session. Sessions are built on demand, meaning that none will be created until they are requested. If pool maxed out and all Sessions are being used, ``acquire_wait_timeout`` sets how long you will wait for a free Session before giving up. 
        - `release` : release the Session and return it to the pool, so that other processes can use it.
        - `destroy` : destroy the Session you pass to it.
        - `stop` : kill all Sessions. Multithreaded.
        
        ## Installation
        
        ```bash
        pip install requestiumpool
        ```
        
        or
        
        ```bash
        pip install git+git://github.com/ConnorSMaynes/requestiumpool
        ```
        
        ## Usage
        
        ```python
        from threading import Thread
        from requestiumpool import RequestiumPool
        
        requestium_args = {
            'webdriver_path' : DRIVER_PATH
            ,'browser':BROWSER_NAME
            ,'default_timeout':15
            }
        # for headless -> 'webdriver_options':{'arguments':['headless'] }
        
        RPool = RequestiumPool( requestium_args, pool_size=2 )
        
        def acquireAndFollow( url ):
            R = RPool.acquire(60)
            if R != None:
                print(url)
                R.driver.get( url )
                RPool.release( R )
            else:
                print( R )           # print None if no browser acquired within timeout
        
        URLs = [ 'https://www.google.com/', 
                    'https://www.stackoverflow.com/', 
                    'https://www.github.com/' ]
        threads = []
        for i in range( 5 ):        
            for url in URLs:
                t = Thread( target=acquireAndFollow, args=(url,) )
                threads.append(t)
                t.start()
        
        for t in threads:           # wait for all urls to be visited
            t.join()
        
        RPool.stop()                # kill all requestium instances
        ```
        
        ### NOTES
        
            `stop()` is multithreaded, but it can take a while with a lot of instances.
            By reusing browsers that are already open, you can significantly reduce time costs.
        
        ## Similar Projects
        
        This project was inspired by another project,
        [Webdriver Pool](https://github.com/Jiramew/webdriver_pool), but for the requestium wrapping around [Requests](https://github.com/requests/requests), [Selenium](https://github.com/SeleniumHQ/selenium), and [Parsel](https://github.com/scrapy/parsel).
        
        ## License
        
        Copyright Â© 2018, [ConnorSMaynes](https://github.com/ConnorSMaynes). Released under the [MIT](https://github.com/ConnorSMaynes/requestiumpool/blob/master/LICENSE).
Platform: all
Classifier: Development Status :: 3 - Alpha
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.6
Classifier: Topic :: Software Development :: Libraries
